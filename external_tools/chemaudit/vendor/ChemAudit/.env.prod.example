# Production Environment Configuration for ChemAudit
#
# SECURITY WARNING: This file contains sensitive configuration.
# - DO NOT commit this file with real credentials
# - DO NOT use default passwords in production
# - Use strong, randomly generated passwords
# - Consider using environment variable management tools (AWS Secrets Manager, HashiCorp Audit, etc.)

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
POSTGRES_USER=chemaudit
# IMPORTANT: Change this to a strong password in production
POSTGRES_PASSWORD=CHANGE_ME_STRONG_PASSWORD_HERE
POSTGRES_DB=chemaudit

# Full database URL - update with your production database credentials
DATABASE_URL=postgresql+asyncpg://chemaudit:CHANGE_ME_STRONG_PASSWORD_HERE@postgres:5432/chemaudit

# =============================================================================
# REDIS CONFIGURATION
# =============================================================================
REDIS_URL=redis://redis:6379/0

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
# Logging level: debug, info, warning, error, critical
LOG_LEVEL=info

# Python settings
PYTHONUNBUFFERED=1
PYTHONDONTWRITEBYTECODE=1

# =============================================================================
# MONITORING
# =============================================================================
# Enable Prometheus metrics endpoint
ENABLE_METRICS=true

# =============================================================================
# CELERY CONFIGURATION
# =============================================================================
# Celery log level: debug, info, warning, error, critical
CELERY_LOG_LEVEL=info

# Number of concurrent workers (adjust based on server resources)
# Recommended: number of CPU cores
CELERY_WORKERS=4

# =============================================================================
# NGINX CONFIGURATION
# =============================================================================
# HTTP and HTTPS ports
HTTP_PORT=80
HTTPS_PORT=443

# =============================================================================
# GRAFANA CONFIGURATION (if using monitoring profile)
# =============================================================================
GRAFANA_USER=admin
# IMPORTANT: Change this to a strong password in production
GRAFANA_PASSWORD=CHANGE_ME_GRAFANA_PASSWORD
GRAFANA_URL=http://localhost:3001

# =============================================================================
# PRODUCTION DEPLOYMENT NOTES
# =============================================================================
#
# 1. SSL/TLS Setup:
#    - Obtain SSL certificates (Let's Encrypt recommended)
#    - Place certificates in ./nginx/ssl/ directory
#    - Update nginx/nginx.conf to enable HTTPS server block
#    - Set certificate paths in nginx configuration
#
# 2. Domain Configuration:
#    - Update server_name in nginx/nginx.conf
#    - Configure DNS A records to point to your server
#    - Update GRAFANA_URL if accessing externally
#
# 3. Security Hardening:
#    - Enable firewall (ufw, iptables)
#    - Restrict access to ports 5432 (PostgreSQL), 6379 (Redis), 9090 (Prometheus)
#    - Only expose ports 80 and 443 to public
#    - Consider IP whitelisting for /metrics and Grafana
#    - Enable HSTS in nginx/ssl-params.conf
#
# 4. Resource Allocation:
#    - Adjust CELERY_WORKERS based on server CPU cores
#    - Set Redis maxmemory based on available RAM
#    - Monitor PostgreSQL connections and adjust max_connections if needed
#
# 5. Backup Strategy:
#    - Regular PostgreSQL backups (pg_dump)
#    - Volume backups for postgres_data, redis_data
#    - Document restore procedures
#
# 6. Monitoring:
#    - Enable monitoring profile: docker-compose --profile monitoring up -d
#    - Configure Prometheus retention based on disk space
#    - Set up alerting rules in Prometheus
#    - Access Grafana at configured GRAFANA_URL
#
# 7. Scaling:
#    - Use docker-compose scale for multiple Celery workers
#    - Consider load balancer for multiple backend instances
#    - Use external PostgreSQL/Redis for high availability
#
# 8. Deployment Commands:
#    # Build frontend first
#    cd frontend && npm run build && cd ..
#    cp -r frontend/dist frontend-dist
#
#    # Start all services
#    docker-compose -f docker-compose.prod.yml up -d
#
#    # Start with monitoring
#    docker-compose -f docker-compose.prod.yml --profile monitoring up -d
#
#    # View logs
#    docker-compose -f docker-compose.prod.yml logs -f
#
#    # Stop all services
#    docker-compose -f docker-compose.prod.yml down
#
# 9. Health Checks:
#    - Backend API: http://your-domain/api/v1/health
#    - Nginx: http://your-domain/health
#    - Prometheus: http://your-domain:9090/-/healthy (if monitoring enabled)
#
# 10. First-Time Setup:
#     - Run database migrations: docker-compose -f docker-compose.prod.yml exec backend alembic upgrade head
#     - Create API keys if needed
#     - Configure Grafana dashboards
